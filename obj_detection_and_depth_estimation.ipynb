{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1053b498-3032-479a-932f-29c721cb4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1632fa58-ca7e-4c97-9f83-bd9bdc97aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import inflect\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    return Image.open(requests.get(url, stream = True).raw)\n",
    "\n",
    "def render_results_in_image(in_pil_img, in_results):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(in_pil_img)\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for prediction in in_results:\n",
    "        x, y = prediction['box']['xmin'], prediction['box']['ymin']\n",
    "        w = prediction['box']['xmax'] - prediction['box']['xmin']\n",
    "        h = prediction['box']['ymax'] - prediction['box']['ymin']\n",
    "\n",
    "        ax.add_patch(plt.Rectangle(\n",
    "            (x,y),\n",
    "            w,\n",
    "            h,\n",
    "            fill = False,\n",
    "            color = 'green',\n",
    "            linewidth = 2\n",
    "        ))\n",
    "\n",
    "        ax.text(\n",
    "            x,\n",
    "            y,\n",
    "            f\"{prediction['label']}: {round(prediction['score']*100,1)}%\",\n",
    "            color = 'red'\n",
    "        )\n",
    "    plt.axis('off')\n",
    "\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format = 'png', bbox_inches = 'tight', pad_inches = 0)\n",
    "    img_buf.seek(0)\n",
    "    modified_image = Image.open(img_buf)\n",
    "    plt.close()\n",
    "    return modified_image\n",
    "\n",
    "\n",
    "def summarize_predictions_natural_language(predictions):\n",
    "    summary = {}\n",
    "    p = inflect.engine()\n",
    "\n",
    "    for prediction in predictions:\n",
    "        label = prediction['label']\n",
    "        if label in summary:\n",
    "            summary[label] += 1\n",
    "        else:\n",
    "            summary[label] = 1\n",
    "\n",
    "    result_string = \"In this image, there are \"\n",
    "    for i, (label, count) in enumerate(summary.items()):\n",
    "        count_string = p.number_to_words(count)\n",
    "        result_string += f\"{count_string} {label}\"\n",
    "\n",
    "        if count > 1:\n",
    "            result_string += 's'\n",
    "        result_string += \" \"\n",
    "\n",
    "        if i == len(summary) - 2:\n",
    "            result_string += \"and \"\n",
    "    result_string = result_string.rstrip(', ') + \".\"\n",
    "    return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894dd5ce-4d20-43d9-8aff-e86176100770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "obj_detector = pipeline(\n",
    "    task = \"object-detection\",\n",
    "    model = \"facebook/detr-resnet-50\"\n",
    ")\n",
    "\n",
    "def get_pipeline_prediction(pil_image):\n",
    "    pipeline_output = obj_detector(pil_image)\n",
    "    processed_image = render_results_in_image(\n",
    "        pil_image, \n",
    "        pipeline_output\n",
    "    )\n",
    "    detection_summary = summarize_predictions_natural_language(pipeline_output)\n",
    "    return processed_image, detection_summary\n",
    "\n",
    "detection_interface = gr.Interface(\n",
    "    fn = get_pipeline_prediction,\n",
    "    inputs = gr.Image(\n",
    "        label = \"Input Image\",\n",
    "        type = 'pil'\n",
    "    ),\n",
    "    outputs = [gr.Image(\n",
    "    label = \"Output image with predicted instances\",\n",
    "    type = 'pil'\n",
    "    ),\n",
    "    gr.Textbox(label=\"Detection Summary\")],\n",
    "    allow_flagging = 'never'\n",
    "    \n",
    ")\n",
    "\n",
    "# Add Markdown content\n",
    "markdown_content_detection = gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; font-family: \"Times New Roman\";'>\n",
    "        <h1 style='color: #FF6347;'>Object Detection with Summary</h1>\n",
    "        <h3 style='color: #4682B4;'>Model: facebook/detr-resnet-50</h3>\n",
    "        <h3 style='color: #32CD32;'>Made By: Md. Mahmudun Nabi</h3>\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine the Markdown content and the demo interface\n",
    "detection_with_markdown = gr.Blocks()\n",
    "with detection_with_markdown:\n",
    "    markdown_content_detection.render()\n",
    "    detection_interface.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d6e1bc-2100-47e8-8d02-4b461c1c8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_estimator = pipeline(task = 'depth-estimation',\n",
    "                           model = 'Intel/dpt-hybrid-midas')\n",
    "\n",
    "def launch(input_image):\n",
    "    out = depth_estimator(input_image)\n",
    "\n",
    "    # resize the prediction\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        out[\"predicted_depth\"].unsqueeze(1),\n",
    "        size=input_image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    # normalize the prediction\n",
    "    output = prediction.squeeze().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    depth = Image.fromarray(formatted)\n",
    "    return depth\n",
    "\n",
    "depth_interface = gr.Interface(launch, \n",
    "                     inputs=gr.Image(type='pil', label = \"Input Image\"), \n",
    "                     outputs=gr.Image(type='pil', label = \"Depth Estimation\"),\n",
    "                              allow_flagging = 'never')\n",
    "\n",
    "# Add Markdown content\n",
    "markdown_content_depth_estimation = gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center; font-family: \"Times New Roman\";'>\n",
    "        <h1 style='color: #FF6347;'>Image Depth Estimation</h1>\n",
    "        <h3 style='color: #4682B4;'>Model: Intel/dpt-hybrid-midas</h3>\n",
    "        <h3 style='color: #32CD32;'>Made By: Md. Mahmudun Nabi</h3>\n",
    "    </div>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Combine the Markdown content and the demo interface\n",
    "depth_estimation_with_markdown = gr.Blocks()\n",
    "with depth_estimation_with_markdown:\n",
    "    markdown_content_depth_estimation.render()\n",
    "    depth_interface.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5e919d-bef1-4d19-a6cc-50fac63c4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine both the app\n",
    "demo = gr.Blocks()\n",
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [detection_with_markdown, depth_estimation_with_markdown],\n",
    "        ['Object Detection', 'Depth Estimation']\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d16ed-5874-4647-bdf6-bcf6beda6374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
